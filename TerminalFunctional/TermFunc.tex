
\textbf{Given}: Terminal functional $g:\Lambda_T \to \R$. Note that the time derivatives for $g$ cannot be defined, but the space derivative can. 
\\
\textbf{Goal}: Find a functional $f$ such that
\begin{itemize}
    \item $f\in \C^K$ for some $K$ (smoothness)
    \item $f(X_T) = g(X_T) $
\end{itemize}
The set $\Gamma^K_g = \Gamma_g \, \cap \, \C^K$, $\Gamma_g = \{f:\Lambda \to \R \, |\, g(X_T) = f(X_T) \}$ is in general not a singleton. Hence we need an additional criterion for $f$.  For instance, solve an optimization program,
$$\min_{f \in \Gamma^K_g} \; l( f),$$
for some loss function $l: \Gamma^K_{g} \to \R$. 
\subsection{Losses}
\subsubsection{$L^2$ projection }
Define for $t\in [0,T]$
$$ l_t(f) = \lVert f(X_t) - g(X_T) \rVert_{L^2(\Q)}^2, $$
which gives the conditioned expectation $f(X_t) = \E^{\Q}[g(X_T) \, |\, X_t]$, i.e. the price of an option with (path-dependent) payoff $g$. We indeed have $f(X_t) \overset{t\uparrow T}{\longrightarrow} g(X_T)$. Then $f$ also minimizes the total distance
$$l(f) = \int_0^T l_t(f)dt = \lVert f(X) - g(X_T) \rVert_{L^2(\Q\, \otimes \,dt)}^2. $$
Why penalizing large deviations from $g(X_T)$ if the terminal constraint is already here?

\subsubsection{Time Variation}
$$l(f) = \E^{\Q}[(\calV f)(X_T)],$$
with the (pathwise) time variation
$$(\calV f)(X_T) = \int_0^T (f(X_t) - \bar{f})^2 dt, \quad \bar{f} = \frac{1}{T} \int_0^T f(X_t)dt. $$

\subsection{Intrinsic Functional}
\begin{definition}
    The intrinsic functional associated to $g:\Lambda_T \to \R$ is defined as $$\iota(X_t) := g(X_{t,T-t}),\quad t\in [0,T].$$
\end{definition}

\bb{Use an operator: $\calI: \R^{\Lambda_T} \to \R^{\Lambda}$, $\calI g =f $.}

Derivatives of $\iota\,$:
\begin{align*}
    \Delta_x \iota(X_t) &= \lim_{h \to 0} \frac{ \iota(X^h_t)- \iota(X_t)}{h}
    = \lim_{h \to 0} \frac{g((X^h)_{t,T-t})- g(X_{t,T-t})}{h}, \quad \text{(bump at $t$)}\\\\
    \Delta_t \iota(X_t) &= \lim_{\delta t \downarrow 0} \frac{ \iota(X_{t,\delta t})- \iota(X_t)}{h}
    = \lim_{\delta t \downarrow 0} \frac{g(X_{t,\delta t + (T-t - \delta t)})- g(X_{t,T-t})}{\delta t} = 0.
\end{align*}
The space derivative of $\iota$ is somewhat similar the Malliavin derivative of $g$, as the whole future path is shocked at time $t$.

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.2]{Figures/IntrinsicFuncDerivative.jpg}
\end{figure}
Now decompose any $f\in \Gamma_g^K$ as
$$f = \iota + h, \quad h\in \Gamma_{\boldsymbol{0}}.$$
When is it optimal to choose $h \equiv 0$?

\begin{example}
Let $g(X_T)=\frac{1}{T}\int_0^T x_s ds$ and $f(X_t) = \frac{1}{t}\int_0^t x_s ds$. The intrinsic functional is 
$$\iota(X_t)  =\frac{1}{T}\int_0^T x_{s\wedge t} ds  = \lambda_t \underbrace{\frac{1}{t}\int_0^t x_s ds}_{\text{average over $[0,t]$}} + (1-\lambda_t)\underbrace{x_t}_{\mathclap{\text{average over $[t,T]$}}}\,, \quad \lambda_t = \frac{t}{T}.$$
 Therefore, 
$$f(X_t) = \iota(X_t) + \frac{T-t}{t}(\iota(X_t)-x_t) = \iota(X_t) +  h(X_t), $$
with $h(X_t) = \left(\frac{1}{t} - \frac{1}{T}\right) \int_0^t (x_s-x_t) ds \overset{t\uparrow T}{\longrightarrow} 0$.

\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.2]{Figures/IntrinsicFuncAsian.jpg}
\end{figure}

\end{example}

\begin{example}
Let $g(X_T)=x^2_T$ and consider its Bachelier price with volatility $\sigma$, i.e. 
$$f_{\sigma}(X_t) = \E^{\Q_{\sigma}}[ x_T^2\, | \, X_t] = \underbrace{x_t^2}_{= \, \iota(X_t)} + \underbrace{\sigma^2(T-t)}_{=\,h_{\sigma}(X_t)}.$$
Hence $f_{\sigma} \overset{\sigma \downarrow 0}{\longrightarrow} \iota$. 
% If $X$ is seen as the log price, then 
% $$f_{\sigma}(X_t) = \quad \lambda_t \underbrace{\frac{T}{t} x_t^2}_{\mathclap{\text{Annualized historical variance}}}\quad  +\quad  (1-\lambda_t) \underbrace{\sigma^2 T}_{\mathclap{\text{Total variance}}} $$
\end{example}

\begin{example}
Let $g(X_T)=\langle X \rangle_T$, $X$ L\'evy process and $f$ is the conditioned expectation. This gives, 
$$f(X_t) = \E^{\Q}[ \langle X \rangle_T\, | \, X_t] = \underbrace{\langle X \rangle_t}_{= \, \iota(X_t)} + \underbrace{\E^{\Q}[\langle X \rangle_{T-t}]}_{=\,h(X_t)}.$$
\end{example}

The time variation reads 
$$\calV f = \calV \iota + \calV h + 2\, (\iota - \bar{\iota},h - \bar{h})_{L^2([0,T])}.$$

% \subsection{Optimality among the extended paths}
% Fix $t <T$ and restrict to the family of functionals
% $$f_Z(X_t) = g(X_t \oplus Z_{T-t}),\quad (X_t \oplus Z_{T-t})(s) = x_{s \wedge t} + Z_{T-t}((s-t) \vee 0)$$
% where $Z_{T-t} \in \Lambda_{T-t} $ is $\sigma(X_t)-$measurable with $Z_{T-t}(0) = 0$. When $Z_{T-t} \equiv 0$, we fall back on the intrinsic functional. 

% \begin{example}
% Take again $g(X_T)=x^2_T$ and choose $Z_{T-t}(s)=  \sigma \frac{s-t}{\sqrt{T-t}} $, $s\in [t,T]$. Then 
% $$f_{Z}(X_t) = (x_t + \sigma \sqrt{T-t})^2 = \E^{\Q_{\sigma}}[ x_T^2\, | \, X_t] + 2x_t \, \sigma \, \sqrt{T-t}.$$
% % If $X$ is seen as the log price, then 
% % $$f_{\sigma}(X_t) = \quad \lambda_t \underbrace{\frac{T}{t} x_t^2}_{\mathclap{\text{Annualized historical variance}}}\quad  +\quad  (1-\lambda_t) \underbrace{\sigma^2 T}_{\mathclap{\text{Total variance}}} $$
% \end{example}

\subsection{Applications}
\begin{itemize}
    \item Hedging: $f(X_t) = \int_0^t \varphi(X_s) dx_s$?
    \item American option: Requires $g$ to be defined on $\Lambda$, in which case we simply take the intrinsic value $g(X_t)$. Replace the cont. value by $$\E^{\Q} [g(X_{t,\tau-t})] = \int_t^T g(X_{t,s-t}) \Q(\tau \in ds)?$$
\end{itemize}