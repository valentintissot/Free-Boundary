\section{Optimal Stopping and Free Boundary Problem}

In this chapter, we assume that $X = (x_t)_{t\in [0,T]}$ is a Markov process, namely
$$\Q (X_{t} \in B \,|\, X_s) = \Q (X_{t} \in B \,|\, x_s), \quad \forall \, B \in \calB(\R^d), \quad t \ge s. $$

taking values in $\R_{+}^d$. 

We consider a family of
stock processes 
$$
S^{t,s}_\tau = (S^{1,t,s}_\tau,\ldots,S^{d,t,s}_\tau) \in \R_+^d, \quad \tau \in [t,T]
$$
representing the stock price paths starting at $s$ at time $t$.
We assume that it is monotone in the $s$-variable.

For a given payoff
$$
\varphi: [0,T]\times \R_+^d \to \R,
$$
we consider the optimal stopping problem with pay-off $\varphi$
and let
$$
v(t,s):= \sup_{\tau \in \cT(t,T) } 
\E\left[ \ \varphi(\tau,S^{t,s}_\tau)\ \right],
$$
where $\cT(t,T)$ is the set of all
stopping times with values in $[t,T]$.

For $t \in [0,T]$, let
$$
\cS_t:= \left\{ s \in \R_+^d\ :\
v(t,s)=\varphi(t,s)\ \right\}
$$
be the \emph{stopping region} at time $t$.

\section{Properties of the Stopping Region}
\subsection{Symmetry}
Many high-dimensional derivatives (basket, rainbow) present a type of symmetry in their payoff.  Under certain conditions (given below), this will carry over to the  stopping region.

\begin{asm} \label{asm: sym}
    The payoff function $\varphi:[0,T]\times \R_+^d \to \R$ is symmetric, in the sense that 
    $$\varphi(t,\cdot) \circ \sigma = \varphi(t,\cdot), \quad \forall \, \sigma \in \calP_d,\, t \in [0,T], $$
    where $\calP_d$ is the set of permutations,
    $$\calP_d = \{\sigma: \R^d_+ \mapsto \R^d_+ \, |\, \sigma(s)=(s_{i_1},...,s_{i_d}), \{i_1,...,i_d\} = \{1,...,d\} \}.$$
\end{asm}

\begin{asm} \label{asm: scale}
    The stock prices scale linearly in the initial value, i.e. $S^{t,s}= s \odot S^{t,\mathds{1}}$ $ \forall \; s \in  \R_+^d$.
\end{asm}

\begin{asm}\label{asm: id}
    The stock prices are identically distributed when starting at the same point, i.e. 
    $$ \sigma(S^{t,\mathds{1}})  \circ \Pb = S^{t,\mathds{1}}  \circ \Pb \quad \forall \,\sigma \in \calP_d.$$
\end{asm}


The following result is now immediate.
\begin{lemma}\label{lem:sym}
If Assumptions \ref{asm: sym}$-$\ref{asm: id} hold, then 
$\sigma(\calS_t)= \calS_t$ for any $\sigma \in \calP_d$.
\end{lemma}
\begin{proof} Let $\sigma \in \calP_d$ and $t \in [0,T]$. Thanks to Assumption \ref{asm: sym}, we can show equivalently that $v(t,\cdot) \circ \sigma =v(t,\cdot)$, where $v$ denotes the value function. 
For $s \in \calS_t$, $\tau \in \calT(t,T)$, this gives
\begin{align*}
    \E_t[\varphi(\tau,S^{t,s}_\tau)] \overset{\ref{asm: sym}}{=} \E_t[\varphi(\tau,\sigma(S^{t,s}_\tau))]
    \overset{\ref{asm: scale}}{=} \E_t[\varphi(\tau,  \sigma(s) \odot \sigma(S^{t,\mathds{1}}_\tau))]
    \overset{\ref{asm: id}}{=} \E_t[\varphi(\tau,S^{t,\sigma(s)}_\tau)],
\end{align*}
and taking the supremum over all stopping times yields $v(t,s)=v(t,\sigma(s))$ as desired.
\end{proof}

Due to the above symmetry, it is therefore sufficient to characterize the set $$\calV_t= \calS_t \cap \calO,$$ where $\calO = \{s\in \R_+^d \,|\, s_1 \geq \ldots \geq s_d\}$ denotes the \textit{cone of ordered stocks}. The whole stopping region can be recovered by shuffling the entries of  elements in $\calV_t$, namely
\begin{equation}\label{eq: recoverS}
    \calS_t = \bigcup_{\sigma \in \calP_d} \sigma(\calV_t). 
\end{equation}

Indeed, if $s\in  \bigcup_{\sigma \in \calP_d} \sigma(\calV_t)$, then $s=\sigma(\tilde{s})$ for some pair $(\sigma,\tilde{s}) \in \calP_d \times \calV_t$. Hence 
$s \in \calS_t$ thanks to Lemma \ref{lem:sym}. Conversely for $s\in \calS_t$, there exists $\varsigma \in \calP_d $ s.t. $\tilde{s}=\varsigma(s) \in \calO$ ($\varsigma$ simply sorts  $s$ in non-increasing order). Lemma \ref{lem:sym} implies that $\tilde{s} \in \calS_t$ ($\Longrightarrow \tilde{s} \in \calV_t$) and defining $ \sigma=\varsigma^{-1}$ leads to
$$s = \sigma (\tilde{s}) \in \bigcup_{\sigma \in \calP_d} \sigma(\calV_t). $$

\subsection{Convexity}

nowing topological properties of the stopping region can help to characterize it more efficiently. We here focus on convexity.

\begin{asm}\label{asm: convlin}
The function $s \mapsto \varphi(t,s)$ is convex on $\R_+^d$ and linear within the stopping region $\calS_t$. 
\end{asm}

Although Assumption \ref{asm: scale} seems restrictive, it is fulfilled by the whole class of index and spread options.

\begin{example}
Consider payoffs of the form
$$\varphi_\eta(t,s) = e^{-rt}(\eta(w^\top s - K))^+, \quad w \in \R^d,  \quad \eta \in \{\pm 1\}.$$
Then $\varphi_\eta(t,\cdot)\big{|}_{\calS_t} >0$  and $\varphi_\eta(t,s) = e^{-rt}\eta(w^\top s - K)$ is indeed linear in $s$ on  $\calS_t $. Basket options  are obtained by setting  $w \in \R_+^d, \quad  w^\top \mathds{1}=1$. Besides, spread options are characterized by the weights $$w_1=-\psi_1 ,\quad  w_i= \frac{\psi_2}{d-1},  \quad 2 \leq i \leq d, \quad \psi_1,\psi_2>0,$$ leading to the payoffs
$$\varphi_\eta(t,s)= e^{-rt} (\eta (\delta(s)-K))^+,
\quad
\delta(s):=   - \psi_1\,s_1 +  \frac{\psi_2}{d-1}\sum_{i=2}^{d}s_i .$$
\end{example}

% \begin{example}
% Consider spread options,
% $$
% \varphi_\eta(t,s)= e^{-rt} (\eta (\delta(s)-K))^+,
% \quad
% \delta(s):=    \frac{\psi_2}{d-1}\sum_{i=2}^{d}s_i - \psi_1\,s_1, \quad  \psi_{1},\psi_{2}>0.
% $$ 
% \end{example}

\begin{lemma}
Under Assumptions \ref{asm: scale} and \ref{asm: convlin},  $\calS_t$ is convex.
\end{lemma}

\begin{proof}
Let $s,s'\in \calS_t$ and $\tilde{s}=\lambda s + (1-\lambda)s'$, $\lambda \in [0,1]$. Then for any $\tau \in \calT(t,T)$,
\begin{align*}
\E_t[\varphi(\tau,S^{t,\tilde{s}}_\tau)] &\overset{\ref{asm: scale}}{=} \E_t[\varphi(\tau,\lambda S^{t,s}_\tau + (1-\lambda) S^{t,s'}_\tau)]\\
    &\overset{\ref{asm: convlin}}{\leq} \lambda \E_t[\varphi(\tau, S^{t,s}_\tau)]
    +
    (1-\lambda)\E_t[\varphi(\tau, S^{t,s'}_\tau)]\\
    &\leq \lambda \varphi(t,s) + (1-\lambda) \varphi(t,s')\\
    &\overset{\ref{asm: convlin}}{=} \varphi(t,\tilde{s}).
\end{align*}
\end{proof}
A convex stopping region is convenient as a continuum of stopping points can be deduced solely based on a few elements of $\calS_t$. For instance, if we identify $\calM = \{s^{(1)},...,s^{(J)}\} \subseteq \calS_t$ using the neural net $\Phi(\cdot;\theta)$,  we then automatically know that the convex hull of $\calM$ belongs to $\calS_t$.

\subsection{Monotonicity in Time}
\begin{asm} \label{asm:StatiMarkov}
The stock prices have stationary increments. 
\end{asm}
\begin{lemma}
If assumptions \ref{asm:StatiMarkov} holds, the exercise boundary  expands over time, i.e. 
$$ \calS_t \subseteq \calS_{t'} \subseteq \calS_T, \quad 0\le t < t' <T,$$
where $\calS_T = \{s \in \R^d_+ \,|\, \varphi(T,s)\ge 0\}$ ($= \R_+^d$ if the payoff is nonnegative).
\end{lemma}
\begin{proof}
Assume that $e^{rt}\varphi(t,s)=\phi(s)$ (i.e. the undiscounted  payoff is time-independent) and write $V(t,\cdot)=e^{rt}v(t,\cdot)$.  Now take $t,t'\in [0,T]$ such that $\Delta_t := t'-t>0$. This gives%\footnote{The shift operator can be used, too.} 
\begin{align*}
    V(t,s)&=\sup_{\tau \in \calT(t,T)} \E_{t,s}[e^{-r(\tau-t)}\phi(S_{\tau})]\\
    &\ge \sup_{\tau \in \calT(t,T-\Delta_t)} \E_{t,s}[e^{-r(\tau-t)}\phi(S_{\tau})]\\
    &\overset{\ref{asm:StatiMarkov}}{=}  \sup_{\tau \in \calT(t',T)} \E_{t',s}[e^{-r(\tau-t')}\phi(S_{\tau})] \\%\qquad (\text{defining the new clock $u=t + \Delta_t$})\\
    &=  V(t',s).
\end{align*}
Hence if $s \in \calS_t$, i.e. $V(t,s)=\phi(s)$, we obtain 
$$\varphi(t',s)= e^{-r t'}\phi(s) = e^{-r t'}V(t,s)\geq  e^{-rt'}V(t',s)=v(t',s),$$
which yields $s \in \calS_{t'}$.
% Note that 
% $v(t,s) \geq \E_{t,s}[v(t',S_{t'})],$
% as $(v(t,S_t))_{t\in [0,T]}$ is a supermartingale. Alternatively,
% \begin{align*}
%     v(t,s) &\geq \sup_{\tau \ge t'} \E_{t,s}[\varphi(\tau,S_{\tau})]\\
%     &= \sup_{\tau \ge t'} \int_{\R_+^d}\E_{t',s'}[\varphi(\tau,S_{\tau})] \Q_{t,s}(S_{t'} \in ds' )\\
%     &\ge  \int_{\R_+^d}v(t',s') \Q_{t,s}(S_{t'} \in ds' )\\ 
%     &=\E_{t,s}[v(t',S_{t'})].
% \end{align*}
% If 
% $$v(t,s)\ge v(t',s) \ge \varphi(t',s)$$

\end{proof}

\flushleft \textbf{Question:}
 For options with zero early exercise premium, one has $\calS_t = \emptyset$ for all $t<T$. Now does $\calS_0 \neq \emptyset$ (hence $\calS_t \neq \emptyset \; \forall t$)
imply that $\calS_t \boldsymbol{\subsetneq} \calS_{t'}$, $t<t'$?   


\begin{corollary}
\label{cor:monot}
The exercise boundary  is monotonic with respect to time.
\end{corollary}
\begin{proof}  Let $x\in \Xi(\R_+^d)$. If assumption $3$ from Mete's note holds, then for any $0\leq t \leq  t' \leq T,$
$$\{a \in \R \, |\, A^{-1}(a,x) \in \calS_t\} \subseteq \{a \in \R \, |\, A^{-1}(a,x) \in \calS_{t'}\},$$
implies $f(t,x) \leq f(t',x).$ 
\end{proof}

\begin{remark}

It is important to note that $t \mapsto f(t,\Xi(S_t))$ might not be monotonic at all! 

Take for instance a basket put on $d=2$ assets and the homeomorphism
 \begin{align*}
 \alpha(s)=\frac{s_1+s_2}{2}, \quad \Xi(s)=s-\alpha(s)=(\Delta,-\Delta)^\top, \quad \Delta = \frac{s_1-s_2}{2}.\\
 \end{align*}
 
 Let $a\in \R_+$. By symmetry of the stopping region (section $1$), if $s^+:=(a+\Delta,a-\Delta)^\top$ belongs to $\calS_t$, so does $s^{-}:= (a-\Delta,a+\Delta)^\top$. Now by convexity of $\calS_t$ (section $2$), this gives 
 $$(a,a)^\top = \frac{s^+ + \, s^{-}}{2} \in \calS_t.$$
 We therefore get for all $ \Delta \in \R$,
 \begin{align*}
     \{a\in \R_+ \,|\, (a+\Delta,a-\Delta)^\top \in \calS_t\} &\subseteq  \{a\in \R_+ \,|\, (a,a)^\top \in \calS_t\},
 \end{align*}
hence $f(t,\boldsymbol{0})&= \sup_{s\in \R^d_+}f(t,\Xi(s))$. Put another way,
\begin{align*}
    \calS_t \subseteq \{s\in \R_+^2 \,|\, \alpha(s)\le f(t,\boldsymbol{0})\}, \quad 0 \le t < T.
\end{align*}


Intuitively, we must even have a strict inclusion as the continuation value, when starting  on the diagonal $\{s\in \R^2_+ \,|\, s_1=s_2\}$, is minimal  \footnote{Indeed, the volatility of $\alpha(S_t)$ is smallest when $S_0^1=S_0^2$ and the vega of American puts is positive.}.
If $S_t=f(t,\boldsymbol{0}) + \boldsymbol{0}$, one can thus find $ t<t'$ close enough, $0<\Delta < f(t,\boldsymbol{0}) $ such that $S_{t'} = S_t + (\Delta,-\Delta)^\top \notin \calS_{t'}$ (see Figure \ref{fig:thr}). Therefore,
\begin{align*}
 f(t',\Xi(S_{t'}))&<\alpha(S_{t'})= f(t,\boldsymbol{0})=f(t,\Xi(S_{t})),
\end{align*}
and
$t \mapsto f(t,\Xi(S_t))$ fails to be non-decreasing.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.3]{Thr_Fct .pdf}
    \caption{Scenario where $t \mapsto f(t,\Xi(S_t))$ fails to be monotonic.}
    \label{fig:thr}
\end{figure}


\end{remark}

\begin{remark}
If we  assume instead that the homeomorphism satisfies
$$\left [ s\in \calS_t,\,  \Xi(s)=\Xi(s'), \,  \alpha(s')\geq \alpha(s) \right]  \Longrightarrow s'\in \calS_t,$$ (e.g. for a call-type payoff), then 
$$f(t,x)= \inf \{a \in \R \, |\, A^{-1}(a,x) \in \calS_t\},$$
and Corollary \ref{cor:monot} implies  that $t\mapsto f(t,x)$ is non-increasing.

\end{remark}
\subsection{Scale Invariance}

Suppose that the payoff involves a constant $K>0$ (usually referred to as the strike). In the sequel, write $\varphi_K$, $v_K$, $\calS_{t,K}$ and $f_K$ for concreteness.
\begin{asm} \label{asm:homo}
The payoff
 is homogeneous in the  sense that $\varphi_{K\gamma}(t,s\gamma )=\gamma \varphi_{K}(t,s)$, $ \gamma>0$. 
\end{asm}

\begin{lemma}\label{lem:homogen}
If assumptions \ref{asm: scale} and \ref{asm:homo} holds,
then 
$$\calS_{t,K}=K\calS_{t,1}:= \{Ks \,|\, s \in \calS_{t,1}\}.$$
\end{lemma}
\begin{proof}
If $\varphi_K$ is homogeneous, then 
$$v_K(t,s) = \sup_{\tau \in \calT(t,T)} \E_t[\varphi_K(\tau,S^{t,s}_{\tau})] = K \,\sup_{\tau \in \calT(t,T)} \E_t[\varphi_1(\tau,S^{t,s/K}_{\tau})]=K\, v_1(t,s/K).$$
This gives
\begin{align*}
    s \in \calS_{t,K} \Longleftrightarrow \varphi_K(t,s) = v_K(t,s)
    \Longleftrightarrow \varphi_1(t,s/K) = v_1(t,s/K)
    \Longleftrightarrow s \in K\calS_{t,1}.
\end{align*}
\end{proof}

\begin{corollary}
Suppose that the inverse function $A^{-1}: \R \times \calR \mapsto \R_+^d$ is homogeneous of degree $1$, i.e. $A^{-1}(a\gamma,x\gamma) = \gamma A^{-1}(a,x)$, $\gamma>0$. Then the exercise boundary satisfies
$$f_K(t,x)= K \, f_1(t,x/K), \quad x \in \calR.$$
\end{corollary}

\begin{proof}
Lemma \ref{lem:homogen} and the definition of $f_K$ directly give
\begin{align*}
    f_K(t,x) &= \sup \{a \in \R \,|\, A^{-1}(a,x) \in \calS_{t,K} \}\\
&= \sup \{a \in \R \,|\, A^{-1}(a,x) \in K\calS_{t,1} \}\\
&= \sup \left \{a \in \R \,|\, A^{-1}(a/K,x/K) \in \calS_{t,1}\right \}\\
&= K f_1(t,x/K).
\end{align*}

\end{proof}

\begin{example}
Consider a basket
option. A valid homeomorphism is  $A=(\alpha,\Xi)$ with  $$\alpha(s) = \frac{1}{d} \sum_{i=1}^d s_i, \quad \Xi(s) = s - \alpha(s).$$
Then the inverse map $A^{-1}(a,x)=a+x$ is clearly homogeneous and the same therefore holds for $f_K$.
\end{example}

\begin{corollary}
If the inverse map satisfies $A^{-1}(a\gamma,x) = \gamma A^{-1}(a,x)$, $\gamma>0$, then 
$$f_K(t,x)= K \, f_1(t,x), \quad x \in \calR.$$
\end{corollary}

\begin{proof}
Same argument as in the previous Corollary.
\end{proof}

\begin{example}
For a max option, take $A=(\alpha,\Xi)$ with  $$\alpha(s) = s_1, \quad \Xi(s) = \frac{s}{s_1}.$$
Then  $A^{-1}(a,x)=a x$ clearly verifies $A^{-1}(a\gamma,x) = \gamma A^{-1}(a,x)$ and thus $f_K(t,x)= K \, f_1(t,x) \; \forall  x \in \calR.$ Notice that this also holds for spread options.
\end{example}

% \begin{corollary}
% The exercise boundary of American, single asset, vanilla options is homogeneous, i.e.
% $$f_K(t)= K \, f_1(t).$$
% \end{corollary}
% \begin{proof} It is clear that vanilla payoffs fulfill assumption \ref{asm:homo}.
% For  American puts, we get
% $$f_K(t) = \sup  \calS_{t,K} = \sup  K  \calS_{t,1} = K \sup \calS_{t,1} = K \, f_1(t).$$
% For  American calls, use infima instead.

\subsection{Regularity}

\section{Neural Parametrization}
\subsection{Algorithm}
\subsection{Convergence}

\section{Applications: Multi-asset American Options}
\subsection{Basket Put Option}
\subsection{Max Call Option}